{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fc0b8c",
   "metadata": {},
   "source": [
    "# njcls job corps â€“ causalpfn vs jc impacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f0b47",
   "metadata": {},
   "source": [
    "_baseline from national job corps study impact report (`01-jcimpacts.pdf`). pulling year-4 employment/earnings targets straight from the pdf for benchmarking against causalpfn._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4432fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import pyreadstat\n",
    "import torch\n",
    "from causalpfn import ATEEstimator, CATEEstimator\n",
    "import causalpfn.causal_estimator as ce\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# keep mac runs stable\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"VECLIB_MAXIMUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "torch.set_num_threads(1)\n",
    "torch.set_num_interop_threads(1)\n",
    "\n",
    "# paths\n",
    "NJCLS_DIR = Path(\"/Users/richardguo/csc494-spatialpfn/economics/njcls\")\n",
    "DATA_DIR = NJCLS_DIR / \"113269-V1\"\n",
    "PDF_PATH = NJCLS_DIR / \"01-jcimpacts.pdf\"\n",
    "RESULTS_DIR = NJCLS_DIR / \"results\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_CSV = RESULTS_DIR / \"njcls_causalpfn_notebook.csv\"\n",
    "\n",
    "# treatment + covariates\n",
    "TREAT_COL = \"TREATMNT\"\n",
    "TREATED_VALUES = {1.0}\n",
    "CONTROL_VALUES = {0.0}\n",
    "COVARIATES = [\n",
    "    \"FEMALE\",\n",
    "    \"AGE_CAT\",\n",
    "    \"RACE_ETH\",\n",
    "    \"HASCHLD\",\n",
    "    \"AFTER_ZT\",\n",
    "    \"ARRST_GR\",\n",
    "    \"EDUC_GR\",\n",
    "    \"AGEGROUP\",\n",
    "    \"INPERS\",\n",
    "    \"IN57\",\n",
    "    \"TYPEAREA\",\n",
    "    \"HS_GED\",\n",
    "]\n",
    "OUTCOME_SPECS = {\n",
    "    \"earnings_per_week_year4\": \"EARNY4\",\n",
    "    \"weeks_employed_pct_year4\": \"PWORKY4\",\n",
    "    \"hours_worked_per_week_year4\": \"HRSWY4\",\n",
    "}\n",
    "DEVICE = \"cpu\"\n",
    "TEST_FRAC = 0.2\n",
    "N_SPLITS = int(os.getenv(\"NJCLS_N_SPLITS\", \"8\"))\n",
    "BASE_SEED = 2025\n",
    "OUTCOME_SEED_OFFSET = {\n",
    "    \"earnings_per_week_year4\": 11,\n",
    "    \"weeks_employed_pct_year4\": 17,\n",
    "    \"hours_worked_per_week_year4\": 23,\n",
    "}\n",
    "\n",
    "# patch causalpfn weak learner for small n splits\n",
    "\n",
    "def _safe_train_weak_learner(self, X, t, y) -> GradientBoostingRegressor:\n",
    "    self.t_transformer = OneHotEncoder(sparse_output=False, categories=\"auto\", drop=\"first\")\n",
    "    T = self.t_transformer.fit_transform(t.reshape(-1, 1))\n",
    "    self._d_t = (T.shape[1],)\n",
    "    feat_arr = np.concatenate((X, 1 - np.sum(T, axis=1).reshape(-1, 1), T), axis=1)\n",
    "    min_leaf = max(1, int(X.shape[0] / 100))\n",
    "    self.stratifier = GradientBoostingRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        min_samples_leaf=min_leaf,\n",
    "        random_state=111,\n",
    "    )\n",
    "    self.stratifier.fit(feat_arr, y)\n",
    "\n",
    "\n",
    "ce.CausalEstimator._train_weak_learner = _safe_train_weak_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9699b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull year-4 targets directly from the impact report pdf\n",
    "with pdfplumber.open(PDF_PATH) as pdf:\n",
    "    raw_text = \" \".join([page.extract_text() or \"\" for page in pdf.pages])\n",
    "clean_text = \" \".join(raw_text.split())\n",
    "\n",
    "patterns = {\n",
    "    \"earnings_per_week_year4\": re.compile(r\"year 4[^.]*?\\$([0-9]+\\.?[0-9]*) per week[^$]*?\\$([0-9]+\\.?[0-9]*) per week\", re.IGNORECASE),\n",
    "    \"weeks_employed_pct_year4\": re.compile(r\"year 4[^%]*?(\\d+\\.?\\d*) percent for the program group[^%]*?(\\d+\\.?\\d*) percent for the control group\", re.IGNORECASE),\n",
    "    \"hours_worked_per_week_year4\": re.compile(r\"year 4[^)]*?(\\d+\\.?\\d*) hours for the program group[^)]*?(\\d+\\.?\\d*) hours for the control group\", re.IGNORECASE),\n",
    "}\n",
    "\n",
    "bench_rows: list[dict] = []\n",
    "for metric, pat in patterns.items():\n",
    "    m = pat.search(clean_text)\n",
    "    if not m:\n",
    "        print(f\"no match found for {metric}\")\n",
    "        continue\n",
    "    pg, ctrl = map(float, m.groups()[:2])\n",
    "    bench_rows.append(\n",
    "        {\n",
    "            \"metric\": metric,\n",
    "            \"program_group\": pg,\n",
    "            \"control_group\": ctrl,\n",
    "            \"reported_diff\": pg - ctrl,\n",
    "            \"pattern\": pat.pattern,\n",
    "        }\n",
    "    )\n",
    "\n",
    "bench_df = pd.DataFrame(bench_rows)\n",
    "bench_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34afbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load analytic files\n",
    "impact_df, impact_meta = pyreadstat.read_sas7bdat(DATA_DIR / \"impact.sas7bdat\")\n",
    "key_df, key_meta = pyreadstat.read_sas7bdat(DATA_DIR / \"key_vars.sas7bdat\")\n",
    "keep_cols = [\"MPRID\", TREAT_COL] + COVARIATES\n",
    "df = impact_df.merge(key_df[keep_cols], on=\"MPRID\", how=\"left\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper utils\n",
    "def set_all_seeds(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "def split_idx(n: int, test_frac: float, seed: int):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(n)\n",
    "    rng.shuffle(idx)\n",
    "    n_test = max(1, int(round(test_frac * n)))\n",
    "    te = idx[:n_test]\n",
    "    tr = idx[n_test:]\n",
    "    return tr, te\n",
    "\n",
    "\n",
    "def standardize_train_apply(Xtr: np.ndarray, Xte: np.ndarray, eps: float = 1e-8):\n",
    "    mu = Xtr.mean(axis=0, keepdims=True)\n",
    "    sd = Xtr.std(axis=0, keepdims=True)\n",
    "    sd = np.where(sd < eps, 1.0, sd)\n",
    "    return (Xtr - mu) / sd, (Xte - mu) / sd\n",
    "\n",
    "\n",
    "def ate_diff_in_means(Y: np.ndarray, T: np.ndarray) -> float:\n",
    "    t1 = (T == 1)\n",
    "    t0 = (T == 0)\n",
    "    if t1.sum() == 0 or t0.sum() == 0:\n",
    "        return float(\"nan\")\n",
    "    return float(Y[t1].mean() - Y[t0].mean())\n",
    "\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> np.ndarray:\n",
    "    X = df[COVARIATES].copy()\n",
    "    cat_cols = [c for c in X.columns if X[c].dtype == \"object\" or str(X[c].dtype).startswith(\"category\")]\n",
    "    if cat_cols:\n",
    "        X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "    for c in X.columns:\n",
    "        if X[c].isna().any():\n",
    "            if np.issubdtype(X[c].dtype, np.number):\n",
    "                X[c] = X[c].fillna(X[c].median())\n",
    "            else:\n",
    "                X[c] = X[c].fillna(\"missing\")\n",
    "    return X.astype(np.float32).to_numpy()\n",
    "\n",
    "\n",
    "def build_treatment(df: pd.DataFrame):\n",
    "    t_series = df[TREAT_COL]\n",
    "    treated = t_series.isin(TREATED_VALUES)\n",
    "    control = t_series.isin(CONTROL_VALUES)\n",
    "    keep = treated | control\n",
    "    t = treated.astype(float)\n",
    "    return t.to_numpy().astype(np.float32), keep.to_numpy()\n",
    "\n",
    "\n",
    "def run_outcome(df: pd.DataFrame, outcome_key: str, y_col: str) -> list[dict]:\n",
    "    rows: list[dict] = []\n",
    "    T_all, keep_t = build_treatment(df)\n",
    "    keep_y = df[y_col].notna().to_numpy()\n",
    "    keep = keep_t & keep_y\n",
    "    dfk = df.loc[keep].copy().reset_index(drop=True)\n",
    "    if dfk.empty:\n",
    "        return rows\n",
    "    T = T_all[keep]\n",
    "    Y = dfk[y_col].astype(np.float32).to_numpy()\n",
    "    X = build_features(dfk)\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    n_treat = int((T == 1).sum())\n",
    "    n_ctrl = int((T == 0).sum())\n",
    "    for split in range(N_SPLITS):\n",
    "        seed = BASE_SEED + 1000 * split + OUTCOME_SEED_OFFSET.get(outcome_key, 0)\n",
    "        set_all_seeds(seed)\n",
    "        tr_idx, te_idx = split_idx(n, TEST_FRAC, seed)\n",
    "        Xtr, Xte = X[tr_idx], X[te_idx]\n",
    "        Ttr, Tte = T[tr_idx], T[te_idx]\n",
    "        Ytr, Yte = Y[tr_idx], Y[te_idx]\n",
    "        Xtr, Xte = standardize_train_apply(Xtr, Xte)\n",
    "        ate_est = ATEEstimator(device=DEVICE)\n",
    "        cate_est = CATEEstimator(device=DEVICE)\n",
    "        ate_est.fit(Xtr, Ttr, Ytr)\n",
    "        cate_est.fit(Xtr, Ttr, Ytr)\n",
    "        ate_hat = float(ate_est.estimate_ate())\n",
    "        cate_hat = np.asarray(cate_est.estimate_cate(Xte), dtype=np.float32)\n",
    "        diff_dm = ate_diff_in_means(Yte, Tte)\n",
    "        rows.append(\n",
    "            {\n",
    "                \"outcome\": outcome_key,\n",
    "                \"y_col\": y_col,\n",
    "                \"split\": split,\n",
    "                \"n_used\": int(n),\n",
    "                \"p\": int(p),\n",
    "                \"treated\": n_treat,\n",
    "                \"control\": n_ctrl,\n",
    "                \"ate_hat\": ate_hat,\n",
    "                \"ate_method\": \"causalpfn_ate\",\n",
    "                \"diff_in_means_test\": diff_dm,\n",
    "                \"cate_mean\": float(cate_hat.mean()),\n",
    "                \"cate_std\": float(cate_hat.std()),\n",
    "                \"device\": DEVICE,\n",
    "                \"seed\": int(seed),\n",
    "                \"test_frac\": float(TEST_FRAC),\n",
    "            }\n",
    "        )\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d4f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run causalpfn across the year-4 outcomes\n",
    "all_rows: list[dict] = []\n",
    "for outcome_key, y_col in OUTCOME_SPECS.items():\n",
    "    if y_col not in df.columns:\n",
    "        print(f\"skip {outcome_key}: {y_col} missing\")\n",
    "        continue\n",
    "    print(f\"running {outcome_key} ({y_col}) ...\")\n",
    "    rows = run_outcome(df, outcome_key, y_col)\n",
    "    if not rows:\n",
    "        print(f\"  no data kept for {outcome_key}\")\n",
    "    all_rows.extend(rows)\n",
    "\n",
    "results_df = pd.DataFrame(all_rows)\n",
    "results_df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"saved splits to {OUT_CSV}\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc46d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate across splits\n",
    "if len(results_df):\n",
    "    agg = (\n",
    "        results_df.groupby([\"outcome\"])\n",
    "        .agg(\n",
    "            n_used=(\"n_used\", \"first\"),\n",
    "            p=(\"p\", \"first\"),\n",
    "            treated=(\"treated\", \"first\"),\n",
    "            control=(\"control\", \"first\"),\n",
    "            ate_mean=(\"ate_hat\", \"mean\"),\n",
    "            ate_std=(\"ate_hat\", \"std\"),\n",
    "            diff_in_means_test=(\"diff_in_means_test\", \"mean\"),\n",
    "            cate_mean=(\"cate_mean\", \"mean\"),\n",
    "            cate_std=(\"cate_std\", \"mean\"),\n",
    "            splits=(\"split\", \"count\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    display(agg)\n",
    "else:\n",
    "    print(\"no results produced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a376e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare causalpfn to published year-4 targets\n",
    "if \"agg\" in locals() and len(agg) and \"bench_df\" in locals() and len(bench_df):\n",
    "    comp = agg.merge(\n",
    "        bench_df,\n",
    "        left_on=\"outcome\",\n",
    "        right_on=\"metric\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"_causalpfn\", \"_pdf\"),\n",
    "    )\n",
    "    comp = comp[\n",
    "        [\n",
    "            \"outcome\",\n",
    "            \"ate_mean\",\n",
    "            \"ate_std\",\n",
    "            \"diff_in_means_test\",\n",
    "            \"program_group\",\n",
    "            \"control_group\",\n",
    "            \"reported_diff\",\n",
    "        ]\n",
    "    ]\n",
    "    display(comp)\n",
    "else:\n",
    "    print(\"no pdf benchmarks matched\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
